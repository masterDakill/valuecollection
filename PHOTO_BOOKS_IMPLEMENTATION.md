# ğŸ“š Photo Books Extract - Guide d'ImplÃ©mentation

**Date**: 19 octobre 2025
**Version**: 1.0 (Initial)
**Statut**: ğŸš§ En cours d'implÃ©mentation

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'Ensemble](#vue-densemble)
2. [Ce Qui A Ã‰tÃ© CrÃ©Ã©](#ce-qui-a-Ã©tÃ©-crÃ©Ã©)
3. [Architecture du Pipeline](#architecture-du-pipeline)
4. [Services Requis](#services-requis)
5. [Endpoint API](#endpoint-api)
6. [Exemple d'IntÃ©gration](#exemple-dintÃ©gration)
7. [Plan d'ImplÃ©mentation Complet](#plan-dimplÃ©mentation-complet)
8. [Tests](#tests)
9. [DÃ©ploiement](#dÃ©ploiement)

---

## ğŸ¯ Vue d'Ensemble

### Objectif

CrÃ©er un endpoint `/api/photo-books-extract` qui :
1. **ReÃ§oit** une photo d'une pile de livres (URL ou base64)
2. **DÃ©tecte** automatiquement N dos de livres (jusqu'Ã  40, recommandÃ© 12-20)
3. **Extrait** les mÃ©tadonnÃ©es (titre, auteur, Ã©diteur, annÃ©e, etc.)
4. **Enrichit** via APIs externes (Google Books, AbeBooks, eBay, Discogs)
5. **DÃ©duplique** avec algorithme de Levenshtein
6. **Sauvegarde** dans Cloudflare D1
7. **Exporte** en CSV si demandÃ©

### Performance Cibles

- â±ï¸ **Latence** : < 30s pour 20 livres
- ğŸ’¾ **Cache hit rate** : > 80% aprÃ¨s quelques jours
- ğŸ’° **Ã‰conomies** : ~70% de coÃ»ts API via cache
- ğŸ¯ **PrÃ©cision** : > 85% de dÃ©tection correcte

---

## âœ… Ce Qui A Ã‰tÃ© CrÃ©Ã©

### 1. SchÃ©mas Zod (`src/schemas/photo-books.schema.ts`)

**Fichier complet crÃ©Ã©** avec :
- âœ… `ImageStackInputSchema` - Validation entrÃ©e (imageUrl | imageBase64 + options)
- âœ… `DetectedBookSchema` - Structure d'un livre dÃ©tectÃ© (25+ champs)
- âœ… `ImageStackResponseSchema` - RÃ©ponse complÃ¨te avec breakdown
- âœ… `PhotoBooksErrorSchema` - Gestion d'erreurs normalisÃ©e
- âœ… Helpers de validation (taille image, MIME type, etc.)

**Utilisation** :
```typescript
import { ImageStackInputSchema, ImageStackResponseSchema } from '../schemas/photo-books.schema';

// Validation entrÃ©e
const validated = ImageStackInputSchema.parse(request.body);

// Validation sortie
const response = ImageStackResponseSchema.parse(result);
```

### 2. Service Vision Multi-Spine (`src/services/vision-multi-spine.service.ts`)

**Fichier complet crÃ©Ã©** avec :
- âœ… DÃ©tection multi-dos via GPT-4o Vision
- âœ… Prompt optimisÃ© pour extraction JSON structurÃ©e
- âœ… Parsing robuste avec fallback
- âœ… Normalisation bbox (0-1)
- âš ï¸ PrÃ©traitement image (stub TODO)

**Utilisation** :
```typescript
import { createVisionMultiSpineService } from '../services/vision-multi-spine.service';

const visionService = createVisionMultiSpineService(OPENAI_API_KEY);
const spines = await visionService.detectMultipleSpines(
  imageUrl,
  null,
  { maxItems: 20, deskew: true, cropStrategy: 'auto' }
);

// RÃ©sultat:
// [
//   { rawText: "The Lord of the Rings J.R.R. Tolkien", bbox: [0.1, 0.2, 0.05, 0.3], confidence: 0.92 },
//   ...
// ]
```

### 3. BibliothÃ¨que Levenshtein (`src/lib/levenshtein.ts`)

**Fichier complet crÃ©Ã©** avec :
- âœ… `levenshteinDistance()` - Distance d'Ã©dition
- âœ… `levenshteinSimilarity()` - Ratio de similaritÃ© (0-1)
- âœ… `normalizeForComparison()` - Normalisation accents/ponctuation
- âœ… `areLikelyDuplicates()` - DÃ©tection multi-critÃ¨res (titre + annÃ©e + auteur)
- âœ… `findDuplicateGroups()` - Groupes de doublons
- âœ… `removeDuplicates()` - Suppression automatique

**Utilisation** :
```typescript
import { removeDuplicates } from '../lib/levenshtein';

const { unique, duplicates, duplicateGroups } = removeDuplicates(
  detectedBooks,
  0.85 // threshold
);

console.log(`${unique.length} livres uniques, ${duplicates.length} doublons`);
```

---

## ğŸ—ï¸ Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/photo-books-extract                                â”‚
â”‚ Input: { imageUrl, imageBase64, options }                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. VALIDATION & CACHE CHECK                                  â”‚
â”‚    - Zod schema validation                                    â”‚
â”‚    - Image size/MIME check (â‰¤10MB, jpg/png/webp)             â”‚
â”‚    - Cache lookup (hash image + options)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. VISION MULTI-SPINE DETECTION                              â”‚
â”‚    Service: VisionMultiSpineService                          â”‚
â”‚    - GPT-4o Vision API call                                  â”‚
â”‚    - Detect N book spines (up to 40)                         â”‚
â”‚    - Extract rawText + bbox per spine                        â”‚
â”‚    Output: VisionSpineResult[]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. NER/NORMALIZATION (PARALLEL)                              â”‚
â”‚    Service: ClaudeNERService (TODO)                          â”‚
â”‚    - Parse rawText â†’ structured fields                       â”‚
â”‚    - Extract: title, author, publisher, year, format         â”‚
â”‚    - Infer category (books, music, artbook, etc.)            â”‚
â”‚    - Detect language (en, fr, es, etc.)                      â”‚
â”‚    Output: PartialDetectedBook[]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ENRICHMENT (PARALLEL, MULTI-API)                          â”‚
â”‚    Service: BooksEnrichmentService (TODO)                    â”‚
â”‚    APIs: Google Books, AbeBooks, eBay, Discogs               â”‚
â”‚    - ISBN lookup (priority)                                  â”‚
â”‚    - Title + author search                                   â”‚
â”‚    - Market pricing (min, median, max)                       â”‚
â”‚    - Rarity score calculation                                â”‚
â”‚    - All with caching (TTL 24h)                              â”‚
â”‚    Output: EnrichedBook[]                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. MULTI-EXPERT CONSOLIDATION                                â”‚
â”‚    Service: ExpertService (EXISTE DÃ‰JÃ€)                      â”‚
â”‚    - Consensus pondÃ©rÃ© (Vision + Claude + APIs)              â”‚
â”‚    - Confidence scoring                                      â”‚
â”‚    - Outlier trimming                                        â”‚
â”‚    Output: ConsolidatedBook[]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. DEDUPLICATION                                             â”‚
â”‚    Lib: levenshtein.ts (CRÃ‰Ã‰)                                â”‚
â”‚    - Multi-criteria matching (title + year + author)         â”‚
â”‚    - Configurable threshold (default 0.85)                   â”‚
â”‚    - Mark duplicates with needs_review flag                  â”‚
â”‚    Output: DedupedBook[]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. DATABASE WRITE                                            â”‚
â”‚    Tables: collection_items, ai_analysis, price_evaluations  â”‚
â”‚    - Bulk insert/UPSERT                                      â”‚
â”‚    - Log sources_used, last_market_check_at                  â”‚
â”‚    - Activity logs pour audit                                â”‚
â”‚    Output: Inserted IDs                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. RESPONSE + EXPORT                                         â”‚
â”‚    - JSON response avec DetectedBook[]                       â”‚
â”‚    - Optional: CSV export (RFC4180, UTF-8-BOM)               â”‚
â”‚    - Cache write (hash image + options)                      â”‚
â”‚    - Metrics logging                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Services Requis

### Services Ã€ CrÃ©er

#### 1. `ClaudeNERService` (TODO)

**Fichier** : `src/services/claude-ner.service.ts`

**ResponsabilitÃ©** : Parser le `rawText` extrait par Vision en champs structurÃ©s.

**Code skeleton** :
```typescript
import Anthropic from '@anthropic-ai/sdk';
import type { DetectedBook } from '../schemas/photo-books.schema';

export class ClaudeNERService {
  private client: Anthropic;

  constructor(apiKey: string) {
    this.client = new Anthropic({ apiKey });
  }

  async parseSpineText(rawText: string): Promise<Partial<DetectedBook>> {
    const prompt = `Parse this book spine text into structured fields:

"${rawText}"

Extract:
- title
- artist_author (author name)
- publisher_label
- year (if visible)
- format (hardcover/paperback/unknown)
- language (ISO 639-1: en, fr, es, etc.)
- category (books, artbook, cinema, music, reference, biography, interviews, unknown)

Return ONLY valid JSON:
{
  "title": "...",
  "artist_author": "...",
  "publisher_label": "...",
  "year": 1984,
  "format": "hardcover",
  "language": "en",
  "category": "books"
}`;

    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 500,
      temperature: 0.1,
      messages: [{ role: 'user', content: prompt }]
    });

    const content = response.content[0];
    if (content.type !== 'text') throw new Error('Unexpected response type');

    // Parse JSON from response
    const jsonMatch = content.text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) throw new Error('No JSON in response');

    return JSON.parse(jsonMatch[0]);
  }

  async parseBatch(rawTexts: string[]): Promise<Partial<DetectedBook>[]> {
    // Parallel processing with Promise.all
    return await Promise.all(
      rawTexts.map(text => this.parseSpineText(text))
    );
  }
}
```

#### 2. `BooksEnrichmentService` (TODO)

**Fichier** : `src/services/books-enrichment.service.ts`

**ResponsabilitÃ©** : Enrichir avec Google Books, AbeBooks, eBay, Discogs.

**Code skeleton** :
```typescript
import type { DetectedBook } from '../schemas/photo-books.schema';
import { BooksService } from './books-service'; // EXISTE DÃ‰JÃ€
import { DiscogsService } from './discogs-service'; // EXISTE DÃ‰JÃ€
import { EbayService } from './ebay-service'; // EXISTE DÃ‰JÃ€
import { APICacheService } from './api-cache-service'; // EXISTE DÃ‰JÃ€

export class BooksEnrichmentService {
  constructor(
    private booksService: BooksService,
    private discogsService: DiscogsService,
    private ebayService: EbayService,
    private cacheService: APICacheService
  ) {}

  async enrichBook(
    book: Partial<DetectedBook>
  ): Promise<Partial<DetectedBook>> {
    const results: Partial<DetectedBook> = { ...book };
    const sources: string[] = [];

    try {
      // 1. Google Books (ISBN priority)
      if (book.isbn_13 || book.isbn_10) {
        const googleData = await this.booksService.searchByISBN(
          book.isbn_13 || book.isbn_10
        );
        if (googleData) {
          results.publisher_label = googleData.publisher;
          results.year = googleData.year;
          sources.push('google_books');
        }
      }

      // 2. AbeBooks (pricing for books)
      if (book.category === 'books') {
        const abeData = await this.searchAbeBooks(book.title, book.artist_author);
        if (abeData) {
          results.estimated_value_min = abeData.minPrice;
          results.estimated_value_median = abeData.medianPrice;
          results.estimated_value_max = abeData.maxPrice;
          results.rarity_score = abeData.rarityScore;
          sources.push('abebooks');
        }
      }

      // 3. Discogs (si musique dÃ©tectÃ©e)
      if (book.category === 'music') {
        const discogsData = await this.discogsService.search(
          `${book.artist_author} ${book.title}`
        );
        if (discogsData) {
          results.publisher_label = discogsData.label;
          results.year = discogsData.year;
          sources.push('discogs');
        }
      }

      // 4. eBay (market trend)
      const ebayData = await this.ebayService.search(
        `${book.title} ${book.artist_author}`
      );
      if (ebayData && ebayData.length > 0) {
        const prices = ebayData.map(item => item.price);
        results.market_trend = this.calculateTrend(prices);
        sources.push('ebay');
      }

      results.sources_used = sources;

    } catch (error) {
      console.error('[Enrichment] Error enriching book:', error);
      results.notes = `Enrichment partially failed: ${error.message}`;
    }

    return results;
  }

  async enrichBatch(books: Partial<DetectedBook>[]): Promise<Partial<DetectedBook>[]> {
    // Parallel avec throttling (max 5 simultanÃ©s)
    const batches = [];
    for (let i = 0; i < books.length; i += 5) {
      const batch = books.slice(i, i + 5);
      batches.push(Promise.allSettled(
        batch.map(book => this.enrichBook(book))
      ));
    }

    const results = await Promise.all(batches);
    return results.flat().map(r => r.status === 'fulfilled' ? r.value : null).filter(Boolean);
  }

  private calculateTrend(prices: number[]): 'up' | 'stable' | 'down' {
    // TODO: ImplÃ©menter logique de tendance
    return 'stable';
  }

  private async searchAbeBooks(title: string, author: string): Promise<any> {
    // TODO: ImplÃ©menter recherche AbeBooks
    // API: https://www.abebooks.com/servlet/DevelopersAPI
    return null;
  }
}
```

#### 3. Export CSV Service (TODO)

**Fichier** : `src/lib/csv-export.ts`

**Code skeleton** :
```typescript
import type { DetectedBook } from '../schemas/photo-books.schema';

/**
 * Export dÃ©tected books to RFC4180 CSV format
 * Includes UTF-8 BOM for Excel compatibility
 */
export function exportToCSV(books: DetectedBook[]): string {
  const BOM = '\uFEFF'; // UTF-8 BOM

  // Headers (stable order)
  const headers = [
    'title',
    'artist_author',
    'publisher_label',
    'year',
    'language',
    'category',
    'format',
    'isbn_10',
    'isbn_13',
    'edition_details',
    'rarity_score',
    'market_trend',
    'estimated_value_min',
    'estimated_value_median',
    'estimated_value_max',
    'sources_used',
    'confidence',
    'notes'
  ];

  // Escape CSV value (RFC4180)
  const escape = (value: any): string => {
    if (value === null || value === undefined) return '';
    const str = String(value);
    if (str.includes(',') || str.includes('"') || str.includes('\n')) {
      return `"${str.replace(/"/g, '""')}"`;
    }
    return str;
  };

  // Build CSV
  const rows = [
    headers.join(','),
    ...books.map(book =>
      headers.map(h => escape(book[h])).join(',')
    )
  ];

  return BOM + rows.join('\n');
}
```

### Services Existants Ã€ RÃ©utiliser

âœ… `ExpertService` (`src/services/ExpertService.ts`) - Consolidation multi-expert
âœ… `APICacheService` (`src/services/api-cache-service.ts`) - Cache API
âœ… `BooksService` (`src/services/books-service.ts`) - Google Books
âœ… `DiscogsService` (`src/services/discogs-service.ts`) - Discogs API
âœ… `EbayService` (`src/services/ebay-service.ts`) - eBay API
âœ… `Logger` (`src/lib/logger.ts`) - Logs structurÃ©s
âœ… `Metrics` (`src/lib/metrics.ts`) - Prometheus metrics
âœ… `Auth` (`src/lib/auth.ts`) - Bearer token auth
âœ… `RateLimit` (`src/lib/rateLimit.ts`) - Rate limiting

---

## ğŸ›£ï¸ Endpoint API

### Route

**Fichier** : `src/routes/photo-books.ts`

**Code complet** :

```typescript
import { Hono } from 'hono';
import { zValidator } from '@hono/zod-validator';
import { ImageStackInputSchema, ImageStackResponseSchema } from '../schemas/photo-books.schema';
import { createVisionMultiSpineService } from '../services/vision-multi-spine.service';
import { removeDuplicates } from '../lib/levenshtein';
import { exportToCSV } from '../lib/csv-export'; // TODO
import type { DetectedBook } from '../schemas/photo-books.schema';

type Bindings = {
  DB: D1Database;
  OPENAI_API_KEY: string;
  ANTHROPIC_API_KEY: string;
  // ... autres bindings
};

export const photoBooksRouter = new Hono<{ Bindings: Bindings }>();

/**
 * POST /api/photo-books-extract
 * Extract multiple books from a single photo
 */
photoBooksRouter.post(
  '/',
  zValidator('json', ImageStackInputSchema),
  async (c) => {
    const startTime = Date.now();
    const requestId = crypto.randomUUID();
    const input = c.req.valid('json');
    const exportFormat = c.req.query('export'); // ?export=csv

    try {
      // 1. VISION: Detect multiple spines
      const visionService = createVisionMultiSpineService(c.env.OPENAI_API_KEY);
      const spines = await visionService.detectMultipleSpines(
        input.imageUrl || null,
        input.imageBase64 || null,
        input.options
      );

      console.log(`[PhotoBooks] Detected ${spines.length} spines`);

      // 2. NER: Parse spine text (TODO: utiliser ClaudeNERService)
      // Pour l'instant, stub simple
      const parsedBooks: Partial<DetectedBook>[] = spines.map(spine => ({
        title: spine.rawText.split(/\s+/).slice(0, 5).join(' '), // Approximation
        bbox: spine.bbox,
        confidence: spine.confidence,
        category: 'unknown',
        format: 'unknown'
      }));

      // 3. ENRICHMENT (TODO: utiliser BooksEnrichmentService)
      // const enrichedBooks = await enrichmentService.enrichBatch(parsedBooks);

      // 4. DEDUPLICATION
      const { unique, duplicates } = removeDuplicates(
        parsedBooks as DetectedBook[],
        input.options.deduplicationThreshold
      );

      console.log(`[PhotoBooks] ${unique.length} unique, ${duplicates.length} duplicates`);

      // 5. DATABASE WRITE (TODO: bulk insert)
      // await c.env.DB.batch([...insert statements]);

      // 6. RESPONSE
      const response: ImageStackResponse = {
        success: true,
        requestId,
        items: unique as DetectedBook[],
        cached: false,
        latencyMs: Date.now() - startTime,
        timestamp: new Date().toISOString()
      };

      // Export CSV si demandÃ©
      if (exportFormat === 'csv') {
        const csv = exportToCSV(unique as DetectedBook[]);
        return c.body(csv, 200, {
          'Content-Type': 'text/csv; charset=utf-8',
          'Content-Disposition': `attachment; filename="detected-books-${requestId}.csv"`
        });
      }

      return c.json(response);

    } catch (error) {
      console.error('[PhotoBooks] Error:', error);
      return c.json({
        success: false,
        error: {
          code: 'INTERNAL_ERROR',
          message: error.message,
          request_id: requestId
        },
        timestamp: new Date().toISOString()
      }, 500);
    }
  }
);
```

### IntÃ©gration dans `src/index.tsx`

Ajouter dans le fichier principal :

```typescript
import { photoBooksRouter } from './routes/photo-books';

// AprÃ¨s les autres routes
app.route('/api/photo-books-extract', photoBooksRouter);
```

---

## ğŸ§ª Tests

### Unit Tests

**Fichier** : `tests/unit/levenshtein.test.ts`

```typescript
import { describe, it, expect } from 'vitest';
import {
  levenshteinDistance,
  levenshteinSimilarity,
  areLikelyDuplicates
} from '../../src/lib/levenshtein';

describe('Levenshtein', () => {
  it('should calculate distance correctly', () => {
    expect(levenshteinDistance('kitten', 'sitting')).toBe(3);
    expect(levenshteinDistance('', '')).toBe(0);
    expect(levenshteinDistance('abc', 'abc')).toBe(0);
  });

  it('should calculate similarity ratio', () => {
    expect(levenshteinSimilarity('abc', 'abc')).toBe(1.0);
    expect(levenshteinSimilarity('', '')).toBe(1.0);
    expect(levenshteinSimilarity('abc', 'xyz')).toBeLessThan(0.5);
  });

  it('should detect duplicates', () => {
    const book1 = { title: 'Harry Potter', artist_author: 'J.K. Rowling', year: 1997 };
    const book2 = { title: 'Harry Potter', artist_author: 'JK Rowling', year: 1997 };
    const book3 = { title: 'Lord of the Rings', artist_author: 'Tolkien', year: 1954 };

    expect(areLikelyDuplicates(book1, book2, 0.85)).toBe(true);
    expect(areLikelyDuplicates(book1, book3, 0.85)).toBe(false);
  });
});
```

### Contract Tests

**Fichier** : `tests/contract/photo-books.test.ts`

```typescript
import { describe, it, expect } from 'vitest';
import { ImageStackInputSchema } from '../../src/schemas/photo-books.schema';

describe('/api/photo-books-extract contract', () => {
  it('should validate correct input', () => {
    const valid = {
      imageUrl: 'https://example.com/books.jpg',
      options: { maxItems: 20, useCache: true }
    };
    expect(() => ImageStackInputSchema.parse(valid)).not.toThrow();
  });

  it('should reject missing image', () => {
    const invalid = { options: {} };
    expect(() => ImageStackInputSchema.parse(invalid)).toThrow();
  });

  it('should enforce maxItems range', () => {
    const invalid = { imageUrl: 'https://example.com/test.jpg', options: { maxItems: 50 } };
    expect(() => ImageStackInputSchema.parse(invalid)).toThrow();
  });
});
```

### E2E Tests

**Fichier** : `tests/e2e/photo-books.e2e.test.ts`

```typescript
import { describe, it, expect } from 'vitest';

describe('Photo Books E2E', () => {
  const BASE_URL = 'http://localhost:3000';

  it('should extract books from photo', async () => {
    const response = await fetch(`${BASE_URL}/api/photo-books-extract`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        imageUrl: 'https://example.com/test-bookshelf.jpg',
        options: { maxItems: 10, useCache: false }
      })
    });

    expect(response.status).toBe(200);
    const data = await response.json();
    expect(data.success).toBe(true);
    expect(Array.isArray(data.items)).toBe(true);
  });

  it('should export CSV', async () => {
    const response = await fetch(`${BASE_URL}/api/photo-books-extract?export=csv`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        imageUrl: 'https://example.com/test-bookshelf.jpg'
      })
    });

    expect(response.status).toBe(200);
    expect(response.headers.get('content-type')).toContain('text/csv');
  });
});
```

---

## ğŸ“¦ DÃ©ploiement

### 1. Variables d'Environnement

Ajouter dans Cloudflare Pages â†’ Settings â†’ Environment Variables :

```bash
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_BOOKS_API_KEY=AIza...
# (autres dÃ©jÃ  configurÃ©es)
```

### 2. Build & Deploy

```bash
# Local test
npm run build
npm run dev:d1

# Deploy to staging
npx wrangler pages deploy dist --project-name evaluateur-collection-pro --branch staging

# Deploy to production
npx wrangler pages deploy dist --project-name evaluateur-collection-pro --branch main
```

### 3. CI/CD GitHub Actions

Fichier `.github/workflows/deploy.yml` (EXISTE DÃ‰JÃ€) gÃ¨re automatiquement le dÃ©ploiement.

---

## âœ… Checklist d'ImplÃ©mentation

### Phase 1 : Core Services âœ…
- [x] SchÃ©mas Zod (photo-books.schema.ts)
- [x] Service Vision Multi-Spine (vision-multi-spine.service.ts)
- [x] BibliothÃ¨que Levenshtein (levenshtein.ts)

### Phase 2 : Services ComplÃ©mentaires ğŸš§
- [ ] ClaudeNERService (claude-ner.service.ts)
- [ ] BooksEnrichmentService (books-enrichment.service.ts)
- [ ] CSV Export (csv-export.ts)

### Phase 3 : Endpoint & Integration ğŸš§
- [ ] Route /api/photo-books-extract (routes/photo-books.ts)
- [ ] IntÃ©gration dans src/index.tsx
- [ ] Middleware auth + rate limit

### Phase 4 : Tests ğŸš§
- [ ] Unit tests (levenshtein, schemas)
- [ ] Contract tests (endpoint validation)
- [ ] E2E tests (full pipeline)

### Phase 5 : Documentation & Deploy ğŸš§
- [ ] OpenAPI spec update
- [ ] README exemples cURL
- [ ] Deploy staging
- [ ] Deploy production

---

## ğŸ“ Prochaines Ã‰tapes RecommandÃ©es

1. **ImplÃ©menter ClaudeNERService** (prioritÃ© haute)
   - Utiliser le skeleton fourni
   - Tester avec des exemples de rawText

2. **CrÃ©er BooksEnrichmentService** (prioritÃ© haute)
   - RÃ©utiliser les services existants (BooksService, DiscogsService, etc.)
   - ImplÃ©menter searchAbeBooks()

3. **CrÃ©er CSV Export** (prioritÃ© moyenne)
   - ImplÃ©menter exportToCSV()
   - Tester avec Excel/Google Sheets

4. **CrÃ©er l'endpoint complet** (prioritÃ© haute)
   - Copier skeleton de routes/photo-books.ts
   - IntÃ©grer tous les services
   - Tester bout en bout

5. **Tests** (prioritÃ© moyenne)
   - Unit tests pour nouveaux services
   - E2E test avec vraie photo

6. **Documentation** (prioritÃ© basse)
   - Mettre Ã  jour README
   - Ajouter exemples cURL

---

## ğŸ¤ Support

Pour questions ou aide :
- ğŸ“§ Contacter Mathieu Chamberland
- ğŸ“š Consulter README.md
- ğŸ” Voir SMART_FEATURES.md pour APIs existantes

---

**DerniÃ¨re mise Ã  jour** : 19 octobre 2025
**Statut** : Fondations crÃ©Ã©es, implÃ©mentation en cours
